{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8266aaa-0de5-4b63-86ef-7b5d8bb7e311",
   "metadata": {},
   "source": [
    "# Import fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d056171-6a9c-46c0-992c-a4bcf879a3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "def _load_and_process_pair(img_path, mask_path, image_size):\n",
    "    img = Image.open(img_path).convert(\"RGB\").resize((image_size[1], image_size[0]))\n",
    "    mask = Image.open(mask_path).convert(\"L\").resize((image_size[1], image_size[0]), resample=Image.NEAREST)\n",
    "    return np.array(img) / 255.0, np.array(mask)\n",
    "\n",
    "def load_images_and_masks(image_dir, mask_dir, image_size=(256, 256), num_workers=40):\n",
    "    image_paths = sorted(glob(os.path.join(image_dir, '*/*.png')))\n",
    "    mask_paths = sorted(glob(os.path.join(mask_dir, '*/*.png')))\n",
    "\n",
    "    print(f\"ðŸ“‚ {len(image_paths)} images trouvÃ©es dans {image_dir}\")\n",
    "    print(f\"ðŸ“‚ {len(mask_paths)} masques trouvÃ©s dans {mask_dir}\")\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        results = list(executor.map(partial(_load_and_process_pair, image_size=image_size), image_paths, mask_paths))\n",
    "\n",
    "    images, masks = zip(*results)\n",
    "    images = np.array(images, dtype=np.float32)\n",
    "    masks = np.array(masks, dtype=np.uint8)\n",
    "    masks = np.expand_dims(masks, axis=-1)\n",
    "\n",
    "    return images, masks\n",
    "\n",
    "\n",
    "# === UNet modulaire ===\n",
    "def double_conv(x, filters):\n",
    "    x = Conv2D(filters, 3, activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(filters, 3, activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "def build_unet(input_shape=(256, 256, 3), num_classes=8, depth=2, base_filters=32):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Encodeur\n",
    "    encoders = []\n",
    "    x = inputs\n",
    "    for i in range(depth):\n",
    "        filters = base_filters * (2 ** i)\n",
    "        x = double_conv(x, filters)\n",
    "        encoders.append(x)\n",
    "        x = MaxPooling2D()(x)\n",
    "\n",
    "    # Bottleneck\n",
    "    x = double_conv(x, base_filters * (2 ** depth))\n",
    "\n",
    "    # Decodeur\n",
    "    for i in reversed(range(depth)):\n",
    "        filters = base_filters * (2 ** i)\n",
    "        x = UpSampling2D()(x)\n",
    "        x = concatenate([x, encoders[i]])\n",
    "        x = double_conv(x, filters)\n",
    "\n",
    "    outputs = Conv2D(num_classes, 1, activation='softmax')(x)\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "\n",
    "# === Fonctions de loss et metrics ===\n",
    "\n",
    "def sparse_categorical_crossentropy_ignore_255(y_true, y_pred):\n",
    "    y_true = tf.squeeze(y_true, axis=-1)\n",
    "    mask = tf.not_equal(y_true, 255)\n",
    "    y_true_clean = tf.where(mask, y_true, tf.zeros_like(y_true))\n",
    "    loss = tf.keras.losses.sparse_categorical_crossentropy(y_true_clean, y_pred)\n",
    "    mask = tf.cast(mask, loss.dtype)\n",
    "    loss = loss * mask\n",
    "    return tf.reduce_sum(loss) / (tf.reduce_sum(mask) + 1e-8)\n",
    "\n",
    "\n",
    "def masked_mean_iou(y_true, y_pred):\n",
    "    num_classes = 8\n",
    "    y_true = tf.squeeze(y_true, axis=-1)\n",
    "    mask = tf.not_equal(y_true, 255)\n",
    "    y_true = tf.where(mask, y_true, 0)\n",
    "    y_pred = tf.argmax(y_pred, axis=-1, output_type=tf.int32)\n",
    "\n",
    "    iou_list = []\n",
    "    for i in range(num_classes):\n",
    "        y_true_i = tf.equal(y_true, i)\n",
    "        y_pred_i = tf.equal(y_pred, i)\n",
    "        intersection = tf.reduce_sum(tf.cast(y_true_i & y_pred_i, tf.float32))\n",
    "        union = tf.reduce_sum(tf.cast(y_true_i | y_pred_i, tf.float32))\n",
    "        iou = tf.math.divide_no_nan(intersection, union)\n",
    "        iou_list.append(iou)\n",
    "    return tf.reduce_mean(iou_list)\n",
    "\n",
    "\n",
    "def masked_dice_coef(y_true, y_pred):\n",
    "    y_true = tf.squeeze(y_true, axis=-1)\n",
    "    mask = tf.not_equal(y_true, 255)\n",
    "    y_true = tf.where(mask, y_true, 0)\n",
    "    y_pred = tf.argmax(y_pred, axis=-1, output_type=tf.int32)\n",
    "\n",
    "    y_true_flat = tf.reshape(y_true, [-1])\n",
    "    y_pred_flat = tf.reshape(y_pred, [-1])\n",
    "    mask_flat = tf.reshape(mask, [-1])\n",
    "\n",
    "    y_true_flat = tf.boolean_mask(y_true_flat, mask_flat)\n",
    "    y_pred_flat = tf.boolean_mask(y_pred_flat, mask_flat)\n",
    "\n",
    "    dice_list = []\n",
    "    num_classes = 8\n",
    "    for i in range(num_classes):\n",
    "        y_true_c = tf.cast(tf.equal(y_true_flat, i), tf.float32)\n",
    "        y_pred_c = tf.cast(tf.equal(y_pred_flat, i), tf.float32)\n",
    "        intersection = tf.reduce_sum(y_true_c * y_pred_c)\n",
    "        dice = (2. * intersection) / (tf.reduce_sum(y_true_c) + tf.reduce_sum(y_pred_c) + 1e-8)\n",
    "        dice_list.append(dice)\n",
    "    return tf.reduce_mean(dice_list)\n",
    "\n",
    "\n",
    "# === EntraÃ®nement ===\n",
    "\n",
    "def train_unet_cityscapes(\n",
    "    image_size=(512, 512),         # ðŸ‘ˆ taille image ajustÃ©e\n",
    "    batch_size=4,\n",
    "    epochs=10,\n",
    "    data_dir=\"/home/romain/work/projet8/notebooks/data\",\n",
    "    experiment_name=\"unet-segmentation-8classes\",\n",
    "    model_name=\"unet_light_cityscapes\",\n",
    "    depth=3,                       # ðŸ‘ˆ profondeur configurable\n",
    "    base_filters=64               # ðŸ‘ˆ capacitÃ© du modÃ¨le\n",
    "):\n",
    "    import mlflow.tensorflow\n",
    "    from mlflow.models.signature import infer_signature\n",
    "\n",
    "    mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    mlflow.tensorflow.autolog()\n",
    "\n",
    "    print(\"ðŸ“¦ Chargement des donnÃ©es d'entraÃ®nement...\")\n",
    "    train_images, train_masks = load_images_and_masks(\n",
    "        os.path.join(data_dir, \"leftImg8bit/train\"),\n",
    "        os.path.join(data_dir, \"masks_8_true/train\"),\n",
    "        image_size=image_size\n",
    "    )\n",
    "\n",
    "    print(\"ðŸ“¦ Chargement des donnÃ©es de validation...\")\n",
    "    val_images, val_masks = load_images_and_masks(\n",
    "        os.path.join(data_dir, \"leftImg8bit/val\"),\n",
    "        os.path.join(data_dir, \"masks_8_true/val\"),\n",
    "        image_size=image_size\n",
    "    )\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        print(\"ðŸ§  CrÃ©ation du modÃ¨le U-Net paramÃ©trable...\")\n",
    "        model = build_unet(\n",
    "            input_shape=(*image_size, 3),\n",
    "            num_classes=8,\n",
    "            depth=depth,\n",
    "            base_filters=base_filters\n",
    "        )\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=Adam(1e-3),\n",
    "            loss=sparse_categorical_crossentropy_ignore_255,\n",
    "            metrics=[\"accuracy\", masked_mean_iou, masked_dice_coef]\n",
    "        )\n",
    "\n",
    "        print(\"ðŸš€ DÃ©marrage de l'entraÃ®nement...\")\n",
    "        history = model.fit(\n",
    "            train_images, train_masks,\n",
    "            validation_data=(val_images, val_masks),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "\n",
    "        print(\"ðŸ’¾ Sauvegarde du modÃ¨le localement au format `.keras`...\")\n",
    "        keras_model_path = f\"{model_name}.keras\"\n",
    "        model.save(keras_model_path)\n",
    "        mlflow.log_artifact(keras_model_path)\n",
    "\n",
    "        print(\"ðŸ“¦ GÃ©nÃ©ration dâ€™un input_example et de la signature...\")\n",
    "        input_example = train_images[:1]\n",
    "        pred_example = model.predict(input_example)\n",
    "        signature = infer_signature(input_example, pred_example)\n",
    "\n",
    "        print(\"ðŸ“¦ Enregistrement du modÃ¨le dans MLflow...\")\n",
    "        mlflow.tensorflow.log_model(\n",
    "            model=model,\n",
    "            artifact_path=\"model\",\n",
    "            registered_model_name=model_name,\n",
    "            input_example=input_example,\n",
    "            signature=signature\n",
    "        )\n",
    "\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae58806-7e9f-466e-b31c-56475c8e7bac",
   "metadata": {},
   "source": [
    "#Â VÃ©rification Ã©tat GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f89350a-13b6-4da9-ab7e-7582ff9998c0",
   "metadata": {},
   "source": [
    "watch -n 1 nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0e133a-a45a-4f81-ad8e-16589c9a9f8c",
   "metadata": {},
   "source": [
    "# 1024 x 2048 - Droplet Digital Ocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3588658-2c1e-4427-b6cd-c81467723a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unet_cityscapes(\n",
    "    image_size=(1024, 2048),\n",
    "    batch_size=10,\n",
    "    epochs=10,\n",
    "    depth=4,\n",
    "    base_filters=64,\n",
    "    model_name=\"unet_1024x2048_d4_f64\",\n",
    "    data_dir=\"/srv/picture_segmentation/projet8_openclassrooms/notebooks/data\",\n",
    "    experiment_name=\"exp_unet_cityscapes_1024x2048_true_masks\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8696ede0-bccf-4efd-804e-da9fe5921111",
   "metadata": {},
   "source": [
    "# TÃ©lÃ©chargement du modÃ¨le entrainÃ©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9251d0c5-885e-43db-af09-f30f2443495d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98ed6e746e774f449913917e1c082dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModÃ¨le tÃ©lÃ©chargÃ© ici : /srv/picture_segmentation/projet8_openclassrooms/notebooks/downloaded_model_384x768/\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "local_path = mlflow.artifacts.download_artifacts(\n",
    "    artifact_uri=\"models:/unet_1024x2048_d4_f64/1\",\n",
    "    dst_path=\"downloaded_model_1024x2048\"\n",
    ")\n",
    "\n",
    "print(f\"ModÃ¨le tÃ©lÃ©chargÃ© ici : {local_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
